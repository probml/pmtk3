
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      --><title>Multi-class Logistic Regression</title><meta name="generator" content="MATLAB 7.9"><meta name="date" content="2010-02-25"><meta name="m-file" content="logregMultinomKernelDemo"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h1>Multi-class Logistic Regression</h1><!--introduction--><p>with basis function expansion. This is a simplification of logregMultinomKernelMinfuncDemo</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Setup Data</a></li><li><a href="#2">Settings</a></li><li><a href="#3">Linear</a></li><li><a href="#4">Polynomial</a></li><li><a href="#5">RBF</a></li><li><a href="#6">Compute training errors</a></li><li><a href="#7">Plot decision boundaries</a></li></ul></div><h2>Setup Data<a name="1"></a></h2><pre class="codeinput">rand(<span class="string">'state'</span>, 0); randn(<span class="string">'state'</span>, 0); <span class="comment">%#ok</span>
nClasses = 5;
nInstances = 100;
nVars = 2;
[X, y] = makeData(<span class="string">'multinomialNonlinear'</span>, nInstances, nVars, nClasses);
</pre><h2>Settings<a name="2"></a></h2><pre class="codeinput">lambda = 1e-2;
addOnes = false;
polyOrder = 2;
rbfScale = 1;
</pre><h2>Linear<a name="3"></a></h2><pre class="codeinput">modelLinear = logregFitL2(X, y, lambda, addOnes);
</pre><h2>Polynomial<a name="4"></a></h2><pre class="codeinput">Kpoly = kernelPoly(X,X,polyOrder);
modelPoly = logregFitL2(Kpoly, y, lambda, addOnes);
</pre><h2>RBF<a name="5"></a></h2><pre class="codeinput">Krbf = rbfKernel(X, X, rbfScale);
modelRBF = logregFitL2(Krbf, y, lambda, addOnes);
</pre><h2>Compute training errors<a name="6"></a></h2><pre class="codeinput">[yhat, prob] = logregPredict(modelLinear, X); <span class="comment">%#ok</span>
trainErr_linear = mean(y~=yhat);
fprintf(<span class="string">'Training error with raw features: %2.f%%\n'</span>, trainErr_linear*100);

[yhat, prob] = logregPredict(modelPoly, Kpoly); <span class="comment">%#ok</span>
trainErr_poly = mean(y~=yhat);
fprintf(<span class="string">'Training error using a polynomial kernal of degree %d: %2.f%%\n'</span>, polyOrder,  trainErr_poly*100);

[yhat, prob] = logregPredict(modelRBF, Krbf);
trainErr_rbf = mean(y~=yhat);
fprintf(<span class="string">'Training error using an RBF kernel with scale %d: %2.f%%\n'</span>, rbfScale, trainErr_rbf*100);
</pre><pre class="codeoutput">Training error with raw features: 49%
Training error using a polynomial kernal of degree 2: 23%
Training error using an RBF kernel with scale 1: 23%
</pre><h2>Plot decision boundaries<a name="7"></a></h2><pre class="codeinput">plotDecisionBoundary(X, y, @(X)logregPredict(modelLinear, X));
title(<span class="string">'Linear Multinomial Logistic Regression'</span>);

predictFcn = @(Xtest) logregPredict(modelPoly, kernelPoly(Xtest, X, polyOrder));
plotDecisionBoundary(X, y, predictFcn);
title(<span class="string">'Kernel-Poly Multinomial Logistic Regression'</span>);

predictFcn = @(Xtest) logregPredict(modelRBF, rbfKernel(Xtest, X, rbfScale));
plotDecisionBoundary(X, y, predictFcn);
title(<span class="string">'Kernel-RBF Multinomial Logistic Regression'</span>);
</pre><img vspace="5" hspace="5" src="logregMultinomKernelDemo_01.png" alt=""> <img vspace="5" hspace="5" src="logregMultinomKernelDemo_02.png" alt=""> <img vspace="5" hspace="5" src="logregMultinomKernelDemo_03.png" alt=""> <p class="footer"><br>
      Published with MATLAB&reg; 7.9<br></p></div><!--
##### SOURCE BEGIN #####
%% Multi-class Logistic Regression 
% with basis function expansion. This is a simplification of
% logregMultinomKernelMinfuncDemo
%% Setup Data
rand('state', 0); randn('state', 0); %#ok
nClasses = 5;
nInstances = 100;
nVars = 2;
[X, y] = makeData('multinomialNonlinear', nInstances, nVars, nClasses);
%% Settings
lambda = 1e-2;
addOnes = false;
polyOrder = 2;
rbfScale = 1;
%% Linear
modelLinear = logregFitL2(X, y, lambda, addOnes);
%% Polynomial
Kpoly = kernelPoly(X,X,polyOrder);
modelPoly = logregFitL2(Kpoly, y, lambda, addOnes);
%% RBF
Krbf = rbfKernel(X, X, rbfScale); 
modelRBF = logregFitL2(Krbf, y, lambda, addOnes);
%% Compute training errors
[yhat, prob] = logregPredict(modelLinear, X); %#ok
trainErr_linear = mean(y~=yhat);
fprintf('Training error with raw features: %2.f%%\n', trainErr_linear*100);

[yhat, prob] = logregPredict(modelPoly, Kpoly); %#ok
trainErr_poly = mean(y~=yhat);
fprintf('Training error using a polynomial kernal of degree %d: %2.f%%\n', polyOrder,  trainErr_poly*100);

[yhat, prob] = logregPredict(modelRBF, Krbf);
trainErr_rbf = mean(y~=yhat);
fprintf('Training error using an RBF kernel with scale %d: %2.f%%\n', rbfScale, trainErr_rbf*100);
%% Plot decision boundaries
plotDecisionBoundary(X, y, @(X)logregPredict(modelLinear, X));
title('Linear Multinomial Logistic Regression');

predictFcn = @(Xtest) logregPredict(modelPoly, kernelPoly(Xtest, X, polyOrder)); 
plotDecisionBoundary(X, y, predictFcn);
title('Kernel-Poly Multinomial Logistic Regression');

predictFcn = @(Xtest) logregPredict(modelRBF, rbfKernel(Xtest, X, rbfScale)); 
plotDecisionBoundary(X, y, predictFcn);
title('Kernel-RBF Multinomial Logistic Regression');


##### SOURCE END #####
--></body></html>